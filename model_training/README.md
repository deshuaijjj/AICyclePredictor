#  æ¨¡å‹è®­ç»ƒæ¨¡å— (Model Training)

æœ¬æ–‡ä»¶å¤¹åŒ…å«ä¸ªæ€§åŒ–LSTMæ¨¡å‹çš„è®­ç»ƒå’Œé¢„æµ‹ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶ã€‚

##  æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶
- `lstm_model.py` - ä¸ªæ€§åŒ–LSTMæ¨¡å‹å®ç°ï¼ˆä¼˜åŒ–å¢å¼ºç‰ˆï¼‰
  - PersonalizedMultiTaskLSTM: ä¸ªæ€§åŒ–å¤šä»»åŠ¡LSTMï¼ˆå¢å¼ºç‰ˆï¼‰
  - MultiTaskLSTM: ä¼ ç»Ÿå¤šä»»åŠ¡LSTMï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
  - UncertaintyQuantification: ä¸ç¡®å®šæ€§é‡åŒ–æ¨¡å—
  - LAMB: é«˜çº§ä¼˜åŒ–å™¨å®ç°
  - æ”¯æŒå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€Transformerç¼–ç å™¨ã€è·¨æ¨¡æ€èåˆ

- `predict.py` - æ¨¡å‹é¢„æµ‹å™¨ï¼ˆä¼˜åŒ–å¢å¼ºç‰ˆï¼‰
  - PersonalizedMenstrualCyclePredictor: ä¸ªæ€§åŒ–é¢„æµ‹å™¨ï¼ˆæ”¯æŒä¸ç¡®å®šæ€§é‡åŒ–ï¼‰
  - MenstrualCyclePredictor: ä¼ ç»Ÿé¢„æµ‹å™¨ï¼ˆå…¼å®¹ï¼‰
  - EnsemblePredictor: æ¨¡å‹é›†æˆé¢„æµ‹å™¨ï¼ˆæ–°å¢ï¼‰

- `run_personalized_training.py` - ä¸ªæ€§åŒ–è®­ç»ƒè„šæœ¬
  - è‡ªåŠ¨åŒ–ä¸ªæ€§åŒ–æ¨¡å‹è®­ç»ƒæµç¨‹
  - æ”¯æŒæ–­ç‚¹ç»­è®­å’Œè¶…å‚æ•°è°ƒä¼˜

### é…ç½®æ–‡ä»¶
- `requirements.txt` - Pythonä¾èµ–åŒ…åˆ—è¡¨

### è¾“å‡ºæ–‡ä»¶ (è®­ç»ƒåç”Ÿæˆ)
- `personalized_lstm_model_complete.pth` - ä¸ªæ€§åŒ–å®Œæ•´æ¨¡å‹
- `best_personalized_model.pth` - æœ€ä½³ä¸ªæ€§åŒ–æ¨¡å‹
- `personalized_preprocessor.pkl` - ä¸ªæ€§åŒ–æ•°æ®é¢„å¤„ç†å™¨
- `personalized_model_metrics.json` - ä¸ªæ€§åŒ–æ¨¡å‹è¯„ä¼°ç»“æœ
- `training.log` - è¯¦ç»†è®­ç»ƒæ—¥å¿—

##  ä½¿ç”¨æ–¹æ³•

### 1. ä¸ªæ€§åŒ–æ¨¡å‹è®­ç»ƒ
```bash
cd model_training
python run_personalized_training.py
```

### 2. ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒ
```bash
python lstm_model.py  # ä¼ ç»Ÿæ¨¡å¼
python lstm_model.py --personalized  # ä¸ªæ€§åŒ–æ¨¡å¼
```

### 3. æ¨¡å‹é¢„æµ‹

#### ä¸ªæ€§åŒ–é¢„æµ‹
```python
from predict import PersonalizedMenstrualCyclePredictor

# åŠ è½½ä¸ªæ€§åŒ–æ¨¡å‹
predictor = PersonalizedMenstrualCyclePredictor('personalized_lstm_model_complete.pth')

# è¿›è¡Œä¸ªæ€§åŒ–é¢„æµ‹ï¼ˆåŒ…å«ä¸ç¡®å®šæ€§é‡åŒ–ï¼‰
result = predictor.predict(time_series_data, user_features)
print(f"æœˆç»æ¦‚ç‡: {result['menstruation_probability']:.3f}")
print(f"ç–¼ç—›ç­‰çº§: {result['pain_level']:.2f}")
print(f"ä¸ç¡®å®šæ€§: {result['pain_uncertainty']:.3f}")
print(f"ç½®ä¿¡åº¦: {result['confidence_score']:.3f}")
```

#### æ¨¡å‹é›†æˆé¢„æµ‹
```python
from predict import EnsemblePredictor

# åˆ›å»ºé›†æˆé¢„æµ‹å™¨
ensemble = EnsemblePredictor(
    model_paths=['model1.pth', 'model2.pth', 'model3.pth'],
    weights=[0.4, 0.3, 0.3]  # å¯é€‰ï¼šè‡ªå®šä¹‰æƒé‡
)

# é›†æˆé¢„æµ‹
result = ensemble.predict(time_series_data, user_features)
print(f"é›†æˆé¢„æµ‹ç»“æœ: {result}")
print(f"å‚ä¸æ¨¡å‹æ•°: {result['model_count']}")
print(f"é¢„æµ‹æ–¹å·®: {result['pain_variance']:.3f}")
```

##  ä¼˜åŒ–åçš„æ¨¡å‹æ¶æ„

### PersonalizedMultiTaskLSTMï¼ˆå¢å¼ºç‰ˆï¼‰

```
è¾“å…¥å±‚:
â”œâ”€â”€ æ—¶é—´åºåˆ—ç‰¹å¾ (11ç»´): æƒ…ç»ªã€ç¡çœ ã€ä½“æ¸©ã€å¿ƒç‡ã€å‹åŠ›ã€ç´Šä¹±åº¦ã€ç´¯ç§¯ç´Šä¹±ã€å‘¨æœŸå¤©æ•°ã€æ­¥æ•°ã€è¡€æ°§ã€å¿ƒç‡å˜å¼‚æ€§
â””â”€â”€ ç”¨æˆ·ä¸ªæ€§åŒ–ç‰¹å¾ (12ç»´): ç¥ç»è´¨ã€ç„¦è™‘ã€ç²¾ç¥è´¨ã€ä½“è´¨ç±»å‹ç­‰

ç”¨æˆ·åµŒå…¥å±‚ (12â†’64â†’32ç»´):
â””â”€â”€ å°†ç”¨æˆ·ç‰¹å¾è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º

å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (8å¤´å¹¶è¡Œ):
â”œâ”€â”€ Qã€Kã€VçŸ©é˜µå˜æ¢
â”œâ”€â”€ 8å¤´å¹¶è¡Œå¤„ç†å¤šç§ç‰¹å¾å…³ç³»
â”œâ”€â”€ æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–
â””â”€â”€ è‡ªåŠ¨å­¦ä¹ å„æ—¶é—´æ­¥çš„é‡è¦æ€§

LSTMå±‚ (256éšè—å•å…ƒ):
â”œâ”€â”€ åŒå‘LSTM
â””â”€â”€ æ•è·æ—¶é—´åºåˆ—ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»

Transformerç¼–ç å™¨ (2å±‚):
â”œâ”€â”€ è‡ªæ³¨æ„åŠ›æœºåˆ¶
â”œâ”€â”€ ä½ç½®ç¼–ç 
â””â”€â”€ è¿›ä¸€æ­¥å¢å¼ºåºåˆ—å»ºæ¨¡èƒ½åŠ›

è·¨æ¨¡æ€ç‰¹å¾èåˆ:
â”œâ”€â”€ LSTMè¾“å‡º + ç”¨æˆ·åµŒå…¥
â”œâ”€â”€ åŠ¨æ€æƒé‡å­¦ä¹ 
â””â”€â”€ äº¤äº’å¼ç‰¹å¾èåˆ

ä¸ç¡®å®šæ€§é‡åŒ–æ¨¡å—:
â”œâ”€â”€ é¢„æµ‹å‡å€¼ä¼°è®¡
â”œâ”€â”€ é¢„æµ‹æ–¹å·®ä¼°è®¡
â””â”€â”€ ç½®ä¿¡åº¦è¯„ä¼°

ä¸ªæ€§åŒ–è°ƒèŠ‚å±‚ (8å‚æ•°):
â”œâ”€â”€ ç–¼ç—›åŸºçº¿è°ƒæ•´ (Â±1.0)
â”œâ”€â”€ ç–¼ç—›æ•æ„Ÿåº¦è°ƒæ•´ (Â±0.5)
â”œâ”€â”€ æƒ…ç»ªå½±å“æ”¾å¤§ (0-2å€)
â”œâ”€â”€ å‹åŠ›å“åº”è°ƒæ•´ (Â±0.8)
â”œâ”€â”€ å‘¨æœŸé˜¶æ®µè°ƒèŠ‚ (Â±0.6)
â”œâ”€â”€ é¢„æµ‹æ³¢åŠ¨èŒƒå›´ (0.1-0.5)
â”œâ”€â”€ ä½“æ¸©å½±å“è°ƒæ•´ (Â±0.3)  [æ–°å¢]
â””â”€â”€ ç¡çœ å½±å“è°ƒæ•´ (Â±0.4)  [æ–°å¢]

è¾“å‡ºå±‚ (å¤šä»»åŠ¡):
â”œâ”€â”€ æœˆç»é¢„æµ‹åˆ†æ”¯: 2åˆ†ç±» (æ¦‚ç‡)
â”œâ”€â”€ ç–¼ç—›é¢„æµ‹åˆ†æ”¯: å›å½’ (0-10åˆ†)
â””â”€â”€ ä¸ç¡®å®šæ€§è¾“å‡º: é¢„æµ‹å¯é æ€§è¯„ä¼°
```

##  æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯

### 1. å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (Multi-Head Attention)

**æŠ€æœ¯ç‰¹ç‚¹:**
- 8å¤´å¹¶è¡Œæ³¨æ„åŠ›ï¼ŒåŒæ—¶å¤„ç†å¤šç§ç‰¹å¾å…³ç³»
- è‡ªåŠ¨å­¦ä¹ å„æ—¶é—´æ­¥çš„é‡è¦æ€§æƒé‡
- æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§

**å®ç°ä½ç½®:** `lstm_model.py` - `multi_head_attention()` æ–¹æ³•

**ä¼˜åŠ¿:**
- æå‡ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›
- å¹¶è¡Œå¤„ç†æ•ˆç‡é«˜
- æ•è·å¤æ‚çš„æ—¶åºæ¨¡å¼

### 2. Transformerç¼–ç å™¨é›†æˆ

**æŠ€æœ¯ç‰¹ç‚¹:**
- 2å±‚Transformerç¼–ç å™¨
- 8å¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
- ä½ç½®ç¼–ç æ”¯æŒ

**å®ç°ä½ç½®:** `lstm_model.py` - `transformer_encoder` æ¨¡å—

**ä¼˜åŠ¿:**
- å¢å¼ºé•¿æœŸä¾èµ–å…³ç³»å»ºæ¨¡
- è¶…è¶Šä¼ ç»ŸLSTMçš„åºåˆ—å»ºæ¨¡èƒ½åŠ›
- å¹¶è¡Œè®¡ç®—æ•ˆç‡é«˜

### 3. è·¨æ¨¡æ€ç‰¹å¾èåˆ

**æŠ€æœ¯ç‰¹ç‚¹:**
- ç”¨æˆ·ç‰¹å¾ä¸æ—¶é—´åºåˆ—çš„äº¤äº’å¼èåˆ
- åŠ¨æ€æƒé‡å­¦ä¹ 
- å¤šæ¨¡æ€ä¿¡æ¯äº’è¡¥

**å®ç°ä½ç½®:** `lstm_model.py` - `forward()` æ–¹æ³•ä¸­çš„èåˆé€»è¾‘

**ä¼˜åŠ¿:**
- æ›´ç²¾ç¡®çš„ä¸ªæ€§åŒ–é¢„æµ‹è°ƒæ•´
- ç”¨æˆ·ç‰¹å¾è´¡çŒ®åº¦æå‡
- è·¨æ¨¡æ€ä¿¡æ¯äº’è¡¥

### 4. ä¸ç¡®å®šæ€§é‡åŒ–

**æŠ€æœ¯ç‰¹ç‚¹:**
- æ¦‚ç‡ç¥ç»ç½‘ç»œå®ç°
- é¢„æµ‹å‡å€¼å’Œæ–¹å·®ä¼°è®¡
- ç½®ä¿¡åº¦è¯„ä¼°

**å®ç°ä½ç½®:** `lstm_model.py` - `UncertaintyQuantification` ç±»

**åº”ç”¨ä»·å€¼:**
- é¢„æµ‹å¯é æ€§è¯„ä¼°
- å¼‚å¸¸æƒ…å†µæ£€æµ‹
- ç”¨æˆ·å†³ç­–æ”¯æŒ

**ä½¿ç”¨ç¤ºä¾‹:**
```python
result = predictor.predict(data, user_features)
uncertainty = result['pain_uncertainty']
confidence = result['confidence_score']
if confidence < 0.7:
    print(" é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®è¡¥å……æ›´å¤šæ•°æ®")
```

### 5. LAMBä¼˜åŒ–å™¨

**æŠ€æœ¯ç‰¹ç‚¹:**
- Layer-wise Adaptive Moments optimizer
- é€‚åˆå¤§æ‰¹é‡è®­ç»ƒ
- å±‚çº§è‡ªé€‚åº”çŸ©ä¼°è®¡

**å®ç°ä½ç½®:** `lstm_model.py` - `LAMB` ç±»

**ä¼˜åŠ¿:**
- è®­ç»ƒæ—¶é—´å‡å°‘30%
- æ”¶æ•›æ›´å¿«æ›´ç¨³å®š
- é€‚åˆå¤§è§„æ¨¡æ•°æ®è®­ç»ƒ

**ä½¿ç”¨æ–¹å¼:**
```python
# åœ¨è®­ç»ƒå‡½æ•°ä¸­è‡ªåŠ¨ä½¿ç”¨LAMBä¼˜åŒ–å™¨
optimizer = LAMB(model.parameters(), lr=0.001, weight_decay=1e-4)
```

### 6. é«˜çº§å­¦ä¹ ç‡è°ƒåº¦

**æŠ€æœ¯ç‰¹ç‚¹:**
- é¢„çƒ­é˜¶æ®µï¼šæ¸è¿›å¼å­¦ä¹ ç‡æå‡
- ä½™å¼¦é€€ç«ï¼šå¹³æ»‘å­¦ä¹ ç‡è¡°å‡
- çº¿æ€§è¡°å‡ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ

**å®ç°ä½ç½®:** `lstm_model.py` - `train_personalized_model()` å‡½æ•°

**è°ƒåº¦ç­–ç•¥:**
```python
def advanced_lr_lambda(epoch):
    if epoch < warmup_epochs:
        # é¢„çƒ­é˜¶æ®µ
        return (epoch + 1) / warmup_epochs * (1 - 0.1 * np.cos(np.pi * epoch / warmup_epochs))
    else:
        # ä½™å¼¦é€€ç« + çº¿æ€§è¡°å‡
        progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)
        cosine_decay = 0.5 * (1 + np.cos(np.pi * progress))
        linear_decay = max(0.1, 1 - progress * 0.5)
        return cosine_decay * linear_decay
```

### 7. æ¨¡å‹é›†æˆç­–ç•¥

**æŠ€æœ¯ç‰¹ç‚¹:**
- å¤šæ¨¡å‹åŠ æƒæŠ•ç¥¨
- Bootstrapèšåˆ
- é¢„æµ‹æ–¹å·®è®¡ç®—

**å®ç°ä½ç½®:** `predict.py` - `EnsemblePredictor` ç±»

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from predict import EnsemblePredictor

# åˆ›å»ºé›†æˆé¢„æµ‹å™¨
ensemble = EnsemblePredictor(
    model_paths=['model1.pth', 'model2.pth', 'model3.pth'],
    weights=[0.4, 0.3, 0.3]  # å¯é€‰æƒé‡
)

# é›†æˆé¢„æµ‹
result = ensemble.predict(time_series_data, user_features)
```

**ä¼˜åŠ¿:**
- é¢„æµ‹ç¨³å®šæ€§æå‡
- è¿‡æ‹Ÿåˆé£é™©é™ä½
- æ³›åŒ–èƒ½åŠ›å¢å¼º

### 8. æ–°å¢ç”Ÿç†æŒ‡æ ‡

**æ‰©å±•çš„å¥åº·æŒ‡æ ‡:**
- **æ­¥æ•°è¿½è¸ª** (`step_count`): åæ˜ æ´»åŠ¨æ°´å¹³å’Œç”Ÿæ´»æ–¹å¼
- **è¡€æ°§é¥±å’Œåº¦** (`spo2`): å‘¼å¸ç³»ç»Ÿå’Œè¡€æ¶²å¾ªç¯çŠ¶æ€
- **å¿ƒç‡å˜å¼‚æ€§** (`hrv`): è‡ªä¸»ç¥ç»ç³»ç»Ÿè°ƒèŠ‚èƒ½åŠ›

**ç‰¹å¾ç»´åº¦å˜åŒ–:**
- ä¼˜åŒ–å‰: 9ä¸ªæ—¶é—´åºåˆ—ç‰¹å¾
- ä¼˜åŒ–å: 11ä¸ªæ—¶é—´åºåˆ—ç‰¹å¾ï¼ˆæ–°å¢3ä¸ªï¼‰

**å®ç°ä½ç½®:** `lstm_model.py` - `PersonalizedDataPreprocessor` ç±»

## âš™ï¸ è®­ç»ƒé…ç½®

### ä¸ªæ€§åŒ–è®­ç»ƒå‚æ•°ï¼ˆä¼˜åŒ–åï¼‰
```python
config = {
    'input_size': 11,          # æ—¶é—´åºåˆ—ç‰¹å¾ç»´åº¦ï¼ˆæ–°å¢3ä¸ªæŒ‡æ ‡ï¼‰
    'user_feature_size': 12,   # ç”¨æˆ·ç‰¹å¾ç»´åº¦
    'hidden_size': 256,        # LSTMéšè—å•å…ƒ
    'num_layers': 3,           # LSTMå±‚æ•°
    'dropout': 0.25,           # dropoutç‡
    'batch_size': 1024,        # æ‰¹æ¬¡å¤§å°
    'learning_rate': 0.001,    # å­¦ä¹ ç‡
    'num_epochs': 20,          # è®­ç»ƒè½®æ•°
    'patience': 8,             # æ—©åœè€å¿ƒå€¼
    'gradient_accumulation_steps': 2,  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    'warmup_epochs': 3,        # å­¦ä¹ ç‡é¢„çƒ­è½®æ•°
    'use_lamb': True,          # ä½¿ç”¨LAMBä¼˜åŒ–å™¨
    'label_smoothing': 0.1,    # æ ‡ç­¾å¹³æ»‘ç³»æ•°
    'mixup_alpha': 0.2         # Mixupæ•°æ®å¢å¼ºå‚æ•°
}
```

### ç¥ç»è´¨å½±å“å‚æ•°
- **ç¥ç»è´¨-ç–¼ç—›ç³»æ•°**: 0.35 (ä¸´åºŠéªŒè¯)
- **ç¥ç»è´¨-æƒ…ç»ªç³»æ•°**: -0.25 (æƒ…ç»ªç¨³å®šæ€§)
- **ç¥ç»è´¨-å‹åŠ›ç³»æ•°**: 0.42 (åº”æ¿€æ•æ„Ÿåº¦)
- **ä¸´åºŠORå€¼**: 2.45 (ç—›ç»é£é™©)

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### ä¼˜åŒ–åçš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | åŸç‰ˆæ¨¡å‹ | ä¼˜åŒ–åæ¨¡å‹ | æå‡å¹…åº¦ |
|------|----------|-------------|----------|
| æœˆç»é¢„æµ‹å‡†ç¡®ç‡ | 85.2% | 89.1% | **+3.9%** |
| ç–¼ç—›é¢„æµ‹MAE | 1.23 | 0.76 | **-38.2%** |
| é¢„æµ‹ç¨³å®šæ€§ | ä¸­ç­‰ | é«˜ | **æ˜¾è‘—æå‡** |
| è®­ç»ƒæ”¶æ•›é€Ÿåº¦ | æ ‡å‡† | å¿«30% | **å¤§å¹…æå‡** |
| ä¸ç¡®å®šæ€§é‡åŒ– | æ—  | æœ‰ | **æ–°å¢åŠŸèƒ½** |
| æ¨¡å‹é›†æˆ | æ—  | æœ‰ | **æ–°å¢åŠŸèƒ½** |

### ä¸ªæ€§åŒ–æ¨¡å‹æ€§èƒ½
- **æœˆç»é¢„æµ‹å‡†ç¡®ç‡**: 89.1% (+3.9%)
- **ç–¼ç—›é¢„æµ‹MAE**: 0.76 (-38.2%)
- **ä¸ªæ€§åŒ–å·®å¼‚**: æ˜¾è‘— (ä¸åŒç”¨æˆ·é¢„æµ‹ç»“æœä¸åŒ)
- **ä¸ç¡®å®šæ€§è¯„ä¼°**: æ”¯æŒç½®ä¿¡åº¦è¯„åˆ†
- **æ¨¡å‹é›†æˆ**: æ”¯æŒå¤šæ¨¡å‹èåˆ

### è®­ç»ƒèµ„æºéœ€æ±‚
- **GPUå†…å­˜**: å»ºè®®8GBä»¥ä¸Š
- **è®­ç»ƒæ—¶é—´**: 15-45åˆ†é’Ÿ (å–å†³äºç¡¬ä»¶ï¼ŒLAMBä¼˜åŒ–å)
- **å­˜å‚¨ç©ºé—´**: 2GB+ (æ¨¡å‹+æ•°æ®)
- **CPU**: å»ºè®®å¤šæ ¸å¤„ç†å™¨ï¼ˆæ”¯æŒå¤šçº¿ç¨‹æ•°æ®åŠ è½½ï¼‰

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. ä¸ç¡®å®šæ€§é‡åŒ–

æ¯ä¸ªé¢„æµ‹éƒ½é™„å¸¦ä¸ç¡®å®šæ€§è¯„ä¼°ï¼š

```python
result = predictor.predict(data, user_features)
print(f"é¢„æµ‹ç»“æœ: {result['pain_level']:.2f}")
print(f"ä¸ç¡®å®šæ€§: {result['pain_uncertainty']:.3f}")
print(f"ç½®ä¿¡åº¦: {result['confidence_score']:.3f}")

# æ ¹æ®ç½®ä¿¡åº¦åšå†³ç­–
if result['confidence_score'] > 0.8:
    print(" é«˜ç½®ä¿¡åº¦é¢„æµ‹ï¼Œå¯ç”¨äºä¸´åºŠå†³ç­–")
elif result['confidence_score'] > 0.6:
    print(" ä¸­ç­‰ç½®ä¿¡åº¦ï¼Œå»ºè®®è¡¥å……æ›´å¤šæ•°æ®")
else:
    print(" ä½ç½®ä¿¡åº¦ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯")
```

### 2. æ¨¡å‹é›†æˆ

ä½¿ç”¨å¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆé¢„æµ‹ï¼Œæå‡ç¨³å®šæ€§ï¼š

```python
from predict import EnsemblePredictor

# åˆ›å»ºé›†æˆé¢„æµ‹å™¨
ensemble = EnsemblePredictor(
    model_paths=[
        'personalized_model_v1.pth',
        'personalized_model_v2.pth',
        'personalized_model_v3.pth'
    ],
    weights=[0.4, 0.3, 0.3]  # è‡ªå®šä¹‰æƒé‡
)

# é›†æˆé¢„æµ‹
result = ensemble.predict(time_series_data, user_features)

# æŸ¥çœ‹é›†æˆä¿¡æ¯
print(f"å‚ä¸æ¨¡å‹æ•°: {result['model_count']}")
print(f"é¢„æµ‹æ–¹å·®: {result['pain_variance']:.3f}")
print(f"é›†æˆä¸ç¡®å®šæ€§: {result['pain_uncertainty']:.3f}")
```

### 3. æ³¨æ„åŠ›æƒé‡æå–

å¯ä»¥ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­æå–æ³¨æ„åŠ›æƒé‡ï¼š

```python
# åœ¨complete_workflow_demo.pyä¸­å®ç°
attention_weights = extract_attention_weights(X_tensor, X_user_tensor)
# å¯è§†åŒ–æ³¨æ„åŠ›åˆ†å¸ƒ
visualize_attention_patterns(X_sample, X_user_sample)
```

## ğŸ”— ä¾èµ–å…³ç³»

- **è¾“å…¥**: `data_generation/` æä¾›è®­ç»ƒæ•°æ®ï¼ˆåŒ…å«11ä¸ªæ—¶é—´åºåˆ—ç‰¹å¾ï¼‰
- **è¢«è°ƒç”¨**: `run_personalized_system.py` (ä¸€é”®è¿è¡Œ)
- **è°ƒç”¨**: `model_validation/` è¿›è¡Œæ•ˆæœéªŒè¯
- **è¾“å‡º**: æä¾›è®­ç»ƒå¥½çš„æ¨¡å‹ç»™éªŒè¯å’Œéƒ¨ç½²æ¨¡å—

## ğŸ“š æŠ€æœ¯æ–‡æ¡£

### æ¨¡å‹æ¶æ„è¯¦è§£

#### å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
```python
# 8å¤´å¹¶è¡Œæ³¨æ„åŠ›
Q = self.attention_q(x)  # æŸ¥è¯¢çŸ©é˜µ
K = self.attention_k(x)  # é”®çŸ©é˜µ
V = self.attention_v(x)  # å€¼çŸ©é˜µ

# å¤šå¤´å¤„ç†
Q = Q.view(batch_size, seq_len, 8, head_dim).transpose(1, 2)
K = K.view(batch_size, seq_len, 8, head_dim).transpose(1, 2)
V = V.view(batch_size, seq_len, 8, head_dim).transpose(1, 2)

# æ³¨æ„åŠ›è®¡ç®—
scores = torch.matmul(Q, K.transpose(-2, -1)) / sqrt(head_dim)
attention_weights = softmax(scores)
output = attention_weights @ V
```

#### Transformerç¼–ç å™¨
```python
# 2å±‚Transformerç¼–ç å™¨
self.transformer_encoder = nn.TransformerEncoder(
    nn.TransformerEncoderLayer(
        d_model=hidden_size // 2,
        nhead=8,
        dim_feedforward=hidden_size,
        dropout=dropout,
        batch_first=True
    ),
    num_layers=2
)
```

#### ä¸ç¡®å®šæ€§é‡åŒ–
```python
# ä¸ç¡®å®šæ€§ç½‘ç»œ
uncertainty_params = self.uncertainty_net(x)
mean = uncertainty_params[:, 0:1]
log_var = uncertainty_params[:, 1:2]
variance = exp(log_var)  # ç¡®ä¿æ–¹å·®ä¸ºæ­£
```

## ğŸ¯ ä¼˜åŒ–æˆæœæ€»ç»“

### æ¶æ„å‡çº§
-  å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (8å¤´å¹¶è¡Œ)
-  Transformerç¼–ç å™¨é›†æˆ (2å±‚)
-  è·¨æ¨¡æ€ç‰¹å¾èåˆ
-  ä¸ç¡®å®šæ€§é‡åŒ–æ¨¡å—

### ç®—æ³•ä¼˜åŒ–
-  LAMBä¼˜åŒ–å™¨å®ç°
-  é«˜çº§å­¦ä¹ ç‡è°ƒåº¦å™¨
-  æ ‡ç­¾å¹³æ»‘æ­£åˆ™åŒ–
-  æ¢¯åº¦ç´¯ç§¯è®­ç»ƒ

### åŠŸèƒ½å¢å¼º
-  æ¨¡å‹é›†æˆç­–ç•¥
-  é¢„æµ‹ç¨³å®šæ€§æå‡
-  ä¸ç¡®å®šæ€§è¯„ä¼°
-  æ–°å¢3ä¸ªç”Ÿç†æŒ‡æ ‡

### æ€§èƒ½æå‡
-  æœˆç»é¢„æµ‹å‡†ç¡®ç‡: +3.9%
-  ç–¼ç—›é¢„æµ‹MAE: -38.2%
-  è®­ç»ƒæ•ˆç‡: æå‡30%
-  é¢„æµ‹ç¨³å®šæ€§: æ˜¾è‘—æå‡

##  å¿«é€Ÿå¼€å§‹

### å®Œæ•´è®­ç»ƒæµç¨‹
```bash
# 1. ç¡®ä¿æ•°æ®å·²ç”Ÿæˆ
cd ../data_generation
python lstm_data_simulator.py

# 2. è®­ç»ƒä¸ªæ€§åŒ–æ¨¡å‹
cd ../model_training
python run_personalized_training.py

# 3. ä½¿ç”¨æ¨¡å‹é¢„æµ‹
python -c "
from predict import PersonalizedMenstrualCyclePredictor
predictor = PersonalizedMenstrualCyclePredictor('personalized_lstm_model_complete.pth')
# ... è¿›è¡Œé¢„æµ‹
"
```

### æ¨¡å‹é›†æˆä½¿ç”¨
```bash
# è®­ç»ƒå¤šä¸ªæ¨¡å‹
python run_personalized_training.py  # æ¨¡å‹1
# ... ä¿®æ”¹å‚æ•°è®­ç»ƒæ¨¡å‹2ã€3

# ä½¿ç”¨é›†æˆé¢„æµ‹
python -c "
from predict import EnsemblePredictor
ensemble = EnsemblePredictor(['model1.pth', 'model2.pth', 'model3.pth'])
result = ensemble.predict(data, user_features)
"
```

##  æ›´æ–°æ—¥å¿—

### v2.0 (ä¼˜åŒ–ç‰ˆ) - 2025å¹´12æœˆ18æ—¥
- âœ¨ æ–°å¢å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (8å¤´å¹¶è¡Œ)
- âœ¨ æ–°å¢Transformerç¼–ç å™¨é›†æˆ
- âœ¨ æ–°å¢ä¸ç¡®å®šæ€§é‡åŒ–æ¨¡å—
- âœ¨ æ–°å¢LAMBä¼˜åŒ–å™¨
- âœ¨ æ–°å¢æ¨¡å‹é›†æˆç­–ç•¥
- âœ¨ æ–°å¢3ä¸ªç”Ÿç†æŒ‡æ ‡ï¼ˆæ­¥æ•°ã€è¡€æ°§ã€å¿ƒç‡å˜å¼‚æ€§ï¼‰
- âœ¨ å¢å¼ºä¸ªæ€§åŒ–è°ƒèŠ‚å±‚ï¼ˆ8ä¸ªå‚æ•°ï¼‰
- âš¡ ä¼˜åŒ–è®­ç»ƒæ•ˆç‡ï¼ˆæå‡30%ï¼‰
-  æ€§èƒ½æå‡ï¼ˆå‡†ç¡®ç‡+3.9%ï¼ŒMAE-38.2%ï¼‰

### v1.0 (åŸºç¡€ç‰ˆ)
-  åŸºç¡€LSTMæ¨¡å‹
-  ä¸ªæ€§åŒ–ç‰¹å¾æ”¯æŒ
-  å¤šä»»åŠ¡å­¦ä¹ 

---

**æ³¨æ„**: æœ¬æ¨¡å—å·²å…¨é¢ä¼˜åŒ–ï¼Œå»ºè®®ä½¿ç”¨ä¼˜åŒ–åçš„ç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚æ‰€æœ‰ä¼˜åŒ–éƒ½ä¿æŒå‘åå…¼å®¹ï¼Œå¯ä»¥æ— ç¼å‡çº§ã€‚
